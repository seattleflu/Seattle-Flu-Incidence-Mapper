"""empty message

Revision ID: 2c92fa01c7ef
Revises: 7d4c7414c89e
Create Date: 2019-05-16 12:39:40.321616

"""
import hashlib
import os
from datetime import datetime
from glob import glob
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
from sqlalchemy import Column, String, DateTime
from sqlalchemy.orm import sessionmaker


# Define our old version of our table
from sqlalchemy.ext.declarative import declarative_base
class PathogenModel(declarative_base()):
    __tablename__ = 'pathogen_model'
    id = sa.Column(sa.String, primary_key=True)
    name = sa.Column(sa.String)
    query_str = sa.Column(sa.String)
    model_type = sa.Column(sa.String)
    rds_key = sa.Column(sa.String)
    created = sa.Column(sa.DateTime, primary_key=True, default=datetime.utcnow)

connection = op.get_bind()
Session = sessionmaker()


revision = '2c92fa01c7ef'
down_revision = '7d4c7414c89e'
branch_labels = None
depends_on = None


old_model_name = 'pathogen_model'
new_model_name = 'generic_model'


def upgrade():

    # ### commands auto generated by Alembic - please adjust! ###
    # sqlite doesn't support drop constraint so
    # create our new table
    from seattle_flu_incidence_mapper.models.generic_model import GenericModel
    GenericModel.metadata.create_all(connection.engine)

    # add our column to our old table and populate the column
    with op.batch_alter_table(old_model_name) as batch_op:
        batch_op.add_column(Column('model_key', String()))
    populate_model_keys()
    delete_old_models()

    old_columns =  ['id', 'name', 'query_str', 'model_type', 'rds_key', 'model_key', 'created']
    col_str = ",".join(old_columns)
    op.execute(f'INSERT INTO {new_model_name} ({col_str}) SELECT {col_str} FROM {old_model_name};')
    op.drop_table(old_model_name)
     ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.rename_table(new_model_name, old_model_name)
    with op.batch_alter_table(old_model_name) as batch_op:
        batch_op.drop_column('model_key')
    # ### end Alembic commands ###


def delete_old_models():
    # cleanup defunc models?
    session = Session(bind=connection)
    from flask import current_app
    base_path = current_app.config.get('MODEL_STORE', '/model_store')
    model_ids = list(session.query(PathogenModel.id).distinct())
    model_ids = set([r for r, in model_ids])
    for file in glob(f"{base_path}/*.csv"):
        if os.path.basename(file)[:-4] not in model_ids:
            print(f'Removing old model {file}')
            os.remove(file)
    session.commit()


def populate_model_keys():
    session = Session(bind=connection)
    from seattle_flu_incidence_mapper.model_store import get_model_file
    model_id_key_hash = {}
    # let's calculate our model keys and rds keys
    for model in session.query(PathogenModel).order_by(PathogenModel.created.desc()).all():
        modelfile = get_model_file(model.id)
        with open(modelfile, 'r') as mf:
            model_key = hashlib.md5(mf.read().encode('utf-8')).hexdigest()
            model.model_key = model_key
        combo_id = model.id + model_key
        if combo_id not in model_id_key_hash:
            model_id_key_hash[model.id + model_key] = True
            session.add(model)
        else:
            session.delete(model)

    # now find models that have duplicate ids/model keys
    # only keep the latest
    session.flush()
    session.commit()